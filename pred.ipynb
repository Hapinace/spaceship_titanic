{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic: Predicting Transported Passengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data plotting and handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing and metrics\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, RobustScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Binary Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled DataFrame objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 72\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSide\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m---> 72\u001b[0m titanic \u001b[38;5;241m=\u001b[39m titanic_transform(titanic)\n\u001b[1;32m     73\u001b[0m submission \u001b[38;5;241m=\u001b[39m titanic_transform(submission)\n\u001b[1;32m     74\u001b[0m titanic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransported\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m titanic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransported\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 41\u001b[0m, in \u001b[0;36mtitanic_transform\u001b[0;34m(data, step, median_age_train, median_expenses_train, scaler, encoder_oh, encoder_l)\u001b[0m\n\u001b[1;32m     38\u001b[0m data[cats] \u001b[38;5;241m=\u001b[39m data[cats]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Unknown booleans will be False or 0\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m!=\u001b[39m submission:\n\u001b[1;32m     42\u001b[0m     data[bools] \u001b[38;5;241m=\u001b[39m data[bools]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     43\u001b[0m     data[bools] \u001b[38;5;241m=\u001b[39m data[bools]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:46\u001b[0m, in \u001b[0;36mOpsMixin.__ne__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ne__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ne__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmp_method(other, operator\u001b[38;5;241m.\u001b[39mne)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:7579\u001b[0m, in \u001b[0;36mDataFrame._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cmp_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   7577\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n\u001b[0;32m-> 7579\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_FRAME(\u001b[38;5;28mself\u001b[39m, other, axis, flex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   7581\u001b[0m     \u001b[38;5;66;03m# See GH#4537 for discussion of scalar op behavior\u001b[39;00m\n\u001b[1;32m   7582\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_frame_op(other, op, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/ops/__init__.py:289\u001b[0m, in \u001b[0;36malign_method_FRAME\u001b[0;34m(left, right, axis, flex, level)\u001b[0m\n\u001b[1;32m    287\u001b[0m             left, right \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39malign(right, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m, level\u001b[38;5;241m=\u001b[39mlevel, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 289\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    290\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only compare identically-labeled DataFrame objects\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m             )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, ABCSeries):\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# axis=1 is default for DataFrame-with-Series op\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     axis \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_get_axis_number(axis) \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Can only compare identically-labeled DataFrame objects"
     ]
    }
   ],
   "source": [
    "# Data importing\n",
    "train_path = 'Data/train.csv'\n",
    "titanic = pd.read_csv(train_path, index_col='PassengerId')\n",
    "\n",
    "submission_path = 'Data/test.csv'\n",
    "submission = pd.read_csv(submission_path, index_col='PassengerId')\n",
    "\n",
    "cats = ['HomePlanet','Destination','Deck','Side']\n",
    "nums_ints = ['Age']\n",
    "nums_floats = ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']\n",
    "bools = ['CryoSleep','VIP']\n",
    "\n",
    "def titanic_transform(\n",
    "        data : pd.DataFrame,\n",
    "        step : int=1,\n",
    "        median_age_train: pd.Series | float | int | None = None,\n",
    "        median_expenses_train: pd.Series | float | int | None = None,\n",
    "        scaler: RobustScaler | None = None,\n",
    "        encoder_oh: OneHotEncoder | None = None,\n",
    "        encoder_l: LabelEncoder | None = None,\n",
    "        prediction: bool = False\n",
    "        ) -> pd.DataFrame:\n",
    "    if step not in [1,2]: raise Exception('Invalid step! Try step=1 or step=2.')\n",
    "    if step == 1:\n",
    "        # Split cabin into separate columns\n",
    "        cabin_columns = ['Deck','CabinNumber','Side']\n",
    "        data[cabin_columns] = (\n",
    "            data['Cabin']\n",
    "            .str\n",
    "            .split('/', expand=True)\n",
    "        )\n",
    "        del data['Cabin']\n",
    "        del data['CabinNumber']\n",
    "        del data['Name']\n",
    "\n",
    "        # Inferential null handling\n",
    "        # Unknown categories will have their own category\n",
    "        data[cats] = data[cats].fillna('Unknown')\n",
    "        data[cats] = data[cats].astype('category')\n",
    "\n",
    "        # Unknown booleans will be False or 0\n",
    "        if prediction != True:\n",
    "            data[bools] = data[bools].fillna(0)\n",
    "            data[bools] = data[bools].astype(int)\n",
    "        return data\n",
    "\n",
    "    if step == 2:\n",
    "        # Numeric null handling\n",
    "\n",
    "        # Unknown ages will be filled with the median of training data (Slightly skewed)\n",
    "        data['Age'] = data['Age'].fillna(median_age_train)\n",
    "        data['Age'] = data['Age'].astype(int)\n",
    "\n",
    "        # Unknown expenses will be filled with the medians of training data (Heavily skewed)\n",
    "        data[nums_floats] = data[nums_floats].fillna(median_expenses_train)\n",
    "        data[nums_floats] = data[nums_floats].astype(float)\n",
    "    \n",
    "        # Normalize and encode data\n",
    "        data[nums_ints + nums_floats] = scaler.transform(data[nums_ints + nums_floats])\n",
    "        data['Deck'] = encoder_l.transform(data['Deck'])\n",
    "        encoded_data_oh = encoder_oh.transform(data[['HomePlanet','Destination','Side']])\n",
    "        encoded_data_oh_df = pd.DataFrame(encoded_data_oh.toarray(), index=data.index, columns=encoder_oh.get_feature_names_out(['HomePlanet','Destination','Side']), dtype=int)\n",
    "        data = pd.concat([data, encoded_data_oh_df], axis=1)\n",
    "\n",
    "        # Delete old categorical data\n",
    "        del data['HomePlanet']\n",
    "        del data['Destination']\n",
    "        del data['Side']\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "titanic = titanic_transform(titanic)\n",
    "submission = titanic_transform(submission)\n",
    "titanic['Transported'] = titanic['Transported'].astype(int)\n",
    "\n",
    "# Train-test split\n",
    "X = titanic.drop(columns='Transported')\n",
    "y = titanic['Transported']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=132)\n",
    "\n",
    "# Get the medians of numeric data\n",
    "median_age_train = X_train['Age'].median()\n",
    "median_expenses_train = X_train[nums_floats].median()\n",
    "\n",
    "# Train scalers and encoders\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train[nums_ints + nums_floats])\n",
    "encoder_oh = OneHotEncoder()\n",
    "encoder_oh.fit(X_train[['HomePlanet','Destination','Side']])\n",
    "encoder_l = LabelEncoder()\n",
    "encoder_l.fit(X_train['Deck'])\n",
    "\n",
    "X_train = titanic_transform(\n",
    "    X_train,\n",
    "    step = 2,\n",
    "    median_age_train = median_age_train,\n",
    "    median_expenses_train = median_expenses_train,\n",
    "    scaler = scaler,\n",
    "    encoder_oh = encoder_oh,\n",
    "    encoder_l = encoder_l\n",
    ")\n",
    "\n",
    "X_test = titanic_transform(\n",
    "    X_test,\n",
    "    step = 2,\n",
    "    median_age_train = median_age_train,\n",
    "    median_expenses_train = median_expenses_train,\n",
    "    scaler = scaler,\n",
    "    encoder_oh = encoder_oh,\n",
    "    encoder_l = encoder_l\n",
    ")\n",
    "\n",
    "submission = titanic_transform(\n",
    "    submission,\n",
    "    step = 2,\n",
    "    median_age_train = median_age_train,\n",
    "    median_expenses_train = median_expenses_train,\n",
    "    scaler = scaler,\n",
    "    encoder_oh = encoder_oh,\n",
    "    encoder_l = encoder_l,\n",
    "    prediction = True\n",
    ")\n",
    "\n",
    "classifiers = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=132),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=132),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=132),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=132),\n",
    "    'LogisticRegression': LogisticRegression(random_state=132, max_iter=1000),\n",
    "    'SVC': SVC(random_state=132)\n",
    "}\n",
    "\n",
    "scores = {\n",
    "    'Classifier':[],\n",
    "    'Accuracy':[],\n",
    "    'F1':[],\n",
    "    'ROC_AUC':[]\n",
    "}\n",
    "\n",
    "for cname, cmodel in classifiers.items():\n",
    "    cmodel.fit(X_train, y_train)\n",
    "    y_pred = cmodel.predict(X_test)\n",
    "    scores['Classifier'].append(cname)\n",
    "    scores['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    scores['F1'].append(f1_score(y_test, y_pred))\n",
    "    scores['ROC_AUC'].append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "scores = pd.DataFrame(scores)\n",
    "scores.set_index(scores['Classifier'], inplace=True)\n",
    "scores.drop(columns='Classifier',axis=1,inplace=True)\n",
    "sns.heatmap(scores, annot=True, cmap='Greens', cbar=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Chosen: **Logistic Regression**  \n",
    "Reason: Highest ROC AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 12\n",
      " Features kept:\n",
      "\n",
      "CryoSleep\n",
      "Age\n",
      "RoomService\n",
      "FoodCourt\n",
      "ShoppingMall\n",
      "Spa\n",
      "VRDeck\n",
      "Deck\n",
      "HomePlanet_Earth\n",
      "HomePlanet_Europa\n",
      "Destination_TRAPPIST-1e\n",
      "Side_S\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_test_score': array([0.62568164, 0.68766107, 0.74144133, 0.76790064, 0.77350853,\n",
       "        0.77595467, 0.78199525, 0.7832896 , 0.78357726, 0.78228126,\n",
       "        0.78673973, 0.79277896, 0.78860858, 0.7916284 , 0.78659605,\n",
       "        0.78788926, 0.78961557, 0.78673921, 0.7884649 , 0.78573212]),\n",
       " 'std_test_score': array([0.01280226, 0.00467531, 0.00926334, 0.01013637, 0.01360594,\n",
       "        0.01039059, 0.00489568, 0.00563976, 0.00807125, 0.0135766 ,\n",
       "        0.00898275, 0.00951616, 0.01194358, 0.00976659, 0.01069053,\n",
       "        0.01099507, 0.00949107, 0.00946686, 0.01046877, 0.01151224]),\n",
       " 'split0_test_score': array([0.62904385, 0.68583753, 0.74694464, 0.77570093, 0.78648454,\n",
       "        0.78145219, 0.79007908, 0.7922358 , 0.79295471, 0.80373832,\n",
       "        0.79942487, 0.79798706, 0.79942487, 0.80014378, 0.79870597,\n",
       "        0.79870597, 0.79726815, 0.79726815, 0.80014378, 0.80086269]),\n",
       " 'split1_test_score': array([0.63191948, 0.68439971, 0.73975557, 0.76635514, 0.76347951,\n",
       "        0.7627606 , 0.77713875, 0.77570093, 0.76994968, 0.76923077,\n",
       "        0.78073329, 0.78792236, 0.77570093, 0.78576564, 0.7721064 ,\n",
       "        0.78073329, 0.78001438, 0.78073329, 0.77929547, 0.78073329]),\n",
       " 'split2_test_score': array([0.60747664, 0.69590223, 0.74478792, 0.7721064 , 0.78073329,\n",
       "        0.78936017, 0.78432782, 0.78504673, 0.78576564, 0.78720345,\n",
       "        0.78432782, 0.79439252, 0.80014378, 0.8015816 , 0.7922358 ,\n",
       "        0.79654925, 0.79870597, 0.7922358 , 0.79151689, 0.79295471]),\n",
       " 'split3_test_score': array([0.64414091, 0.68943206, 0.75125809, 0.77641984, 0.78504673,\n",
       "        0.78145219, 0.78145219, 0.78432782, 0.78936017, 0.78504673,\n",
       "        0.79439252, 0.80589504, 0.79511143, 0.79511143, 0.79439252,\n",
       "        0.79367362, 0.79583034, 0.7922358 , 0.79798706, 0.78720345]),\n",
       " 'split4_test_score': array([0.61582734, 0.68273381, 0.72446043, 0.74892086, 0.75179856,\n",
       "        0.7647482 , 0.77697842, 0.77913669, 0.77985612, 0.76618705,\n",
       "        0.77482014, 0.77769784, 0.77266187, 0.77553957, 0.77553957,\n",
       "        0.76978417, 0.77625899, 0.77122302, 0.77338129, 0.76690647])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=132)\n",
    "# Recursive Feature Elimination using Logistic Regression\n",
    "rfe = RFECV(estimator=model, n_jobs=-1)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    f'Optimal number of features: {rfe.n_features_}\\n',\n",
    "    f'Features kept:\\n'\n",
    ")\n",
    "for i,col in zip(range(X_train.shape[1]),X_train.columns):\n",
    "    if rfe.support_[i]:\n",
    "        print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6954, 12) (1739, 12)\n"
     ]
    }
   ],
   "source": [
    "# Transform data\n",
    "X_train = rfe.transform(X_train)\n",
    "X_test = rfe.transform(X_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8174665607204344\n"
     ]
    }
   ],
   "source": [
    "# Re-evaluate model\n",
    "model = LogisticRegression(random_state=132, max_iter=10000, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hapi/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hapi/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hapi/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/hapi/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/hapi/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of LogisticRegression must be a str among {'sag', 'lbfgs', 'liblinear', 'newton-cg', 'saga', 'newton-cholesky'}. Got 'lib-linear' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/hapi/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.85765423 0.85765299        nan 0.85902428 0.86076553 0.86843491\n",
      " 0.86843615        nan 0.87000773 0.87014423 0.86875778 0.86875861\n",
      "        nan 0.86928491 0.86961869 0.86835183 0.86835059        nan\n",
      " 0.86896524 0.86947762 0.8682716  0.86825589        nan 0.86891354\n",
      " 0.86944246 0.86824514 0.86824845        nan 0.86890402 0.86943667]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: LogisticRegression(C=0.01, max_iter=10000, n_jobs=-1, random_state=132,\n",
      "                   solver='saga') Best parameters: {'C': 0.01, 'solver': 'saga'}\n",
      " Best score: 0.8701442299397891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=132, max_iter=10000, n_jobs=-1)\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'C': np.logspace(-3,2,6),\n",
    "    'solver': ['lbfgs','newton-cg','lib-linear','sag','saga']\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "# Results\n",
    "print(\n",
    "    f'Best estimator: {grid_search.best_estimator_}',\n",
    "    f'Best parameters: {grid_search.best_params_}\\n',\n",
    "    f'Best score: {grid_search.best_score_}\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_search.best_estimator_\n",
    "prediction = model.predict(submission)\n",
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
